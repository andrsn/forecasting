\documentclass{article}

\title{Modelling Attention}

\author{Sean Anderson, Tom Stafford and Mike Dewar}

\begin{document}
    
    \maketitle
    
    \section{Introduction}
    
    Clicking on links is the primary method of interaction we have with material on the internet. In aggregate, these clicks represent a huge opportunity for studying human behaviour. Making the link between clicks and human behaviour, though, is not straightforward.
    
    By far and away the most studied aspect of aggregate clicks is the `click through rate': the probability that a user will click on an advert after having seen it \cite{}. Click through rate analysis attempts to infer, and subsequently modify, the behaviour of humans who are clicking on links. This work models behaviour in aggregate across multiple clicks, with the aim of being able to predict an individual's behaviour on a single page.
    
% a user's affinity for a product
    
    While these studies are certainly starting to lead to a deeper understanding of human behaviour when faced with adverts, they generally don't aim to learn more general browsing behaviours. Our focus in this paper is to model attention, and to learn something universal about this slice of human behaviour.
    
    Our approach is highly data driven: using clicks captured by the link shortening service bit.ly from across the social web we have created generative, dynamic models that are able to track the click rate on individual links. While these models are useful for prediction, we show in this paper that they are also a `way in' to some fundamental aspects of human behaviour on the internet. 
    
    \section{Data}
    
    Data is provided by bit.ly, a link shortening service. bit.ly is a popular method for creating shortened versions of long URLs which direct a user's click through an http 301 redirect to the desired page. The typical use case is that user $a$ creates a link to a page they would like to share on the social web\footnote{defined loosely as the ecosystem of websites around twitter.com and facebook.com} and then publishes it on their platform of choice. User $b$ then sees that published link and clicks on it, and it is this click that is captured by bit.ly. Here we are interested in the time of each click, broken down by referring domain and target URL. 
    
    \subsection{Clicks}
    
    We define a click as an http 301 redirect event from either facebook.com or twitter.com to a target domain. From bit.ly's data set we store the time of a click, denoted $t$, which has a resolution of seconds, we store the referring domain, denoted $i \in \{\textrm{facebook.com}, \textrm{twitter.com} \}$, and the target domain, denoted $j$. We group this data into clicks from a specific domain to a specific URL: 
    \begin{equation}
        c_{ij} = \{t_1, t_2, \ldots, t_{N_{ij}}\}
    \end{equation}
    where $N_{ij}$ is the total number of clicks from referrer $i$ to URL $j$. 
    
    
    \subsection{Click Rates}
    
    \section{Modelling}
    
    \subsection{Time Series Modelling}
    
    \subsection{Model Predicted Output}
    
    \section{Results}
    
    \subsection{Time Constants}
    
\end{document}